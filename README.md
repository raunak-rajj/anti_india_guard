# anti_india_guard


This project analyzes social media data to detect **anti-India posts**, perform **sentiment analysis**, and identify whether accounts are **bots or humans**.  
It provides **interactive visualizations** using **Streamlit** and **Plotly**.

---

##  Features

- **Sentiment Analysis**
  - Classifies posts into sentiment categories (Positive, Neutral, Negative).
  - Histogram visualization shows sentiment distribution in **percentages**.

- **Anti-India Content Detection**
  - Custom keyword-based detection function:
  - Counts and highlights anti-India posts.
  - Bar chart visualization with proportion of total posts.

- **Bot vs Human Classification**
  - Detects if a user is likely a bot or human.
  - Donut pie chart visualization of bot-human distribution.

- **Interactive Dashboards**
  - Built using **Streamlit** and **Plotly** for real-time, interactive charts.

---

##  Visualizations

- Sentiment distribution (percentages).  
- Anti-India posts (bar chart with counts + percentage).  
- Bot vs Human distribution (donut pie chart).  

---

##  Tech Stack

- **Python**
- **Pandas** (data processing)
- **Plotly Express** (interactive charts)
- **Streamlit** (dashboard & UI)

---

##  NLP model

- "cardiffnlp/twitter-roberta-base-sentiment-latest"


##  Requirements

Create a virtual environment and install dependencies:


## Notes on Running the Pipeline

- The file **`fetch_twitter.py`** is only meant for testing whether the Twitter fetching functionality is working correctly. It is not part of the main pipeline.

- For development and demonstration, the rest of the pipeline has been tested using **dummy tweets** generated by `dummy_tweets.py`. By default, the pipeline reads these dummy tweets.

- If you want to run the **full pipeline on real-time raw tweets** fetched from Twitter:
  1. First reset the pipeline or refresh the web page
  2. Then open **`clean_text.py`** and replace the following line:
     ```python
     df = pd.read_csv("data/dummy_tweets.csv")
     ```
     with:
     ```python
     df = pd.read_csv("data/raw_tweets.csv")
     ```
This switch ensures the pipeline processes **actual tweets** instead of the dummy dataset.

- This repository also contains a **`twitter_cookies.json`** file.  
  It was generated using a **test Twitter account** purely for experimentation and development purposes.

## How to Run

1. Install **Python 3.9+**  
   - [Download Python](https://www.python.org/downloads/) and make sure it is added to your PATH.  
   - Verify installation:
     ```bash
     python --version
     ```

2. Create a virtual environment and install dependencies:
   ```bash
   python -m venv venv
   ```

   ```bash
   source venv/bin/activate     # On macOS/Linux
   ```
   
   ```bash
   venv\Scripts\activate        # On Windows
   ```
   ```bash
   pip install -r requirements.txt
   ```

3. Pre-download the RoBERTa sentiment model (so app doesnâ€™t hang later)
   ```bash
   python -c "from transformers import AutoTokenizer, AutoModelForSequenceClassification; \
   AutoTokenizer.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment-latest'); \
   AutoModelForSequenceClassification.from_pretrained('cardiffnlp/twitter-roberta-base-sentiment-latest')"
   ```

4. Run the web app:
   ```bash
   streamlit run app/demo_app.py
   ```